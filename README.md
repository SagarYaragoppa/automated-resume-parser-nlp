# ğŸ“„ Resume Parser Using NLP

## ğŸ” Project Overview

This project implements an **NLP-based Resume Parsing System** that automatically extracts structured information from unstructured resumes (PDF or text format).
The system uses a **fine-tuned pretrained Named Entity Recognition (NER) model** along with **rule-based NLP techniques** to accurately identify key resume details.

The final output is stored in a clean **JSON format**, making it suitable for integration with Applicant Tracking Systems (ATS) or HR analytics pipelines.

---

## ğŸ¯ Key Objectives

* Convert unstructured resume text into structured data
* Extract key information such as:

  * Name
  * Contact details
  * Skills
  * Education
  * Experience
* Improve extraction accuracy using **custom rules and fine-tuned NER**

---

## ğŸ§  Approach & Methodology

The system follows a **hybrid NLP pipeline**:

1. **Resume Input**
   Accepts resumes in PDF or TXT format.

2. **Text Extraction**
   Extracts raw text from PDF resumes using PDF parsing libraries.

3. **Text Preprocessing**
   Cleans and normalizes text for better NLP performance.

4. **Named Entity Recognition (NER)**
   Uses a **pretrained spaCy NER model**, fine-tuned on resume-specific data to identify entities such as:

   * PERSON
   * ORGANIZATION
   * DATE
   * SKILL
   * DEGREE

5. **Rule-Based Extraction**
   Applies regular expressions and keyword-based rules to extract:

   * Email address
   * Phone number
   * Skills and section-specific data

6. **Entity Normalization & Validation**
   Removes duplicates and standardizes extracted entities.

7. **Structured Output Generation**
   Stores extracted information in structured **JSON format**.

---

## ğŸ—ï¸ Project Architecture

```
resume-parser/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ resumes/           # Input resume files
â”‚   â””â”€â”€ annotations/       # Labeled training data for NER
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ner_model/         # Fine-tuned spaCy NER model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pdf_extractor.py   # PDF to text extraction
â”‚   â”œâ”€â”€ preprocess.py      # Text cleaning & normalization
â”‚   â”œâ”€â”€ ner.py             # NER inference logic
â”‚   â”œâ”€â”€ rules.py           # Regex & rule-based extraction
â”‚   â””â”€â”€ parser.py          # End-to-end pipeline
â”‚
â”œâ”€â”€ output/
â”‚   â””â”€â”€ parsed_resume.json # Final structured output
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technologies Used

* **Python**
* **spaCy (NLP & NER)**
* **NLTK (optional preprocessing)**
* **PyPDF2 / pdfplumber**
* **Regular Expressions (Regex)**
* **JSON**

---

## ğŸ¤– Model Details

* **Base Model:** spaCy pretrained English NER model
* **Enhancement:** Fine-tuned on resume-specific annotated data
* **Training Type:** Transfer learning (no training from scratch)

This approach ensures:

* Faster development
* Better accuracy with limited data
* Industry-aligned ML practices

---

## ğŸ“¤ Sample Output

```json
{
  "name": "Rahul Sharma",
  "email": "rahul.sharma@gmail.com",
  "phone": "9876543210",
  "skills": ["Python", "Machine Learning", "NLP", "SQL"],
  "education": [
    "B.Tech in Computer Science, XYZ University (2019â€“2023)"
  ],
  "experience": [
    "AI Intern - Infosys (Jan 2023 â€“ Jun 2023)"
  ]
}
```

---

## ğŸš€ How to Run the Project

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run parser
python src/parser.py
```

---

## ğŸ“ˆ Results & Accuracy

* Improved entity extraction accuracy using custom rules
* Reduced false positives compared to raw NER output
* Successfully parsed resumes with varied formats

---

## ğŸ”® Future Enhancements

* Resumeâ€“job description matching
* Skill gap analysis
* Streamlit-based UI
* Multilingual resume support
* Integration with GenAI for resume summarization

---

## ğŸ‘¤ Author

**Sagar Yaragoppa**
B.Tech AIML Student
Project built as a continuation of Neural Network fundamentals and applied NLP learning.

